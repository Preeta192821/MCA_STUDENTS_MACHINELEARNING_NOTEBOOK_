{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In this sense, we can say that Natural Language Processing (NLP) is the sub-field of Computer Science especially Artificial Intelligence (AI) that is concerned about enabling computers to understand and process human language.', 'Technically, the main task of NLP would be to program computers for analyzing and processing huge amount of natural language data.', 'the main task of NLP would be to program computers for analyzing and processing huge amount of natural language data.']\n",
      "\n",
      "In this sense, we can say that Natural Language Processing (NLP) is the sub-field of Computer Science especially Artificial Intelligence (AI) that is concerned about enabling computers to understand and process human language.\n",
      "Technically, the main task of NLP would be to program computers for analyzing and processing huge amount of natural language data.\n",
      "the main task of NLP would be to program computers for analyzing and processing huge amount of natural language data.\n"
     ]
    }
   ],
   "source": [
    "text = \"In this sense, we can say that Natural Language Processing (NLP) is the sub-field of Computer Science especially Artificial Intelligence (AI) that is concerned about enabling computers to understand and process human language. Technically, the main task of NLP would be to program computers for analyzing and processing huge amount of natural language data. the main task of NLP would be to program computers for analyzing and processing huge amount of natural language data.\"\n",
    "# tokenization\n",
    "\n",
    "sentence = nltk.sent_tokenize(text)\n",
    "print(sentence)\n",
    "print(\"\")\n",
    "for i in sentence:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python is a scripting language.', 'why we learn python.', 'what is data science.']\n",
      "{'language', '.', 'scripting', 'what', 'learn', 'we', 'data', 'is', 'science', 'why', 'python', 'a'}\n",
      "['python', 'is', 'a', 'scripting', 'language.', 'why', 'we', 'learn', 'python.', 'what', 'is', 'data', 'science.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "p = \"python is a scripting language. why we learn python. what is data science.\"\n",
    "print(nltk.sent_tokenize(p))# sentence tokenization\n",
    "\n",
    "print(set(nltk.word_tokenize(p)))# word tokenization and set is used to remove the duplicay of words\n",
    "print(p.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "#these are the total stopwords in english\n",
    "stop_word = (stopwords.words(\"english\"))\n",
    "print(stop_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When we look at the positive aspect of social media.', 'we find numerous advantages.', 'The most important being a great device for education.', 'All the information one requires is just a click away.', 'Students can educate themselves on various topics using social media.', 'Moreover, live lectures are now possible because of social media.', 'You can attend a lecture happening in America while sitting in India.', 'Furthermore, as more and more people are distancing themselves from newspapers, they are depending on social media for news.', 'You are always updated on the latest happenings of the world through it.', 'A person becomes more socially aware of the issues of the world.']\n"
     ]
    }
   ],
   "source": [
    "text = '''When we look at the positive aspect of social media. we find numerous advantages. The most important being a great device for education. \n",
    "          All the information one requires is just a click away. Students can educate themselves on various topics using social media.\n",
    "          Moreover, live lectures are now possible because of social media. You can attend a lecture happening in America while sitting in India.\n",
    "          Furthermore, as more and more people are distancing themselves from newspapers, they are depending on social media for news. You are always updated on the latest happenings of the world through it. A person becomes more socially aware of the issues of the world.\n",
    "        '''\n",
    "print(nltk.sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'being', 'it', 'news', 'people', 'issues', 'Furthermore', 'great', 'the', 'we', 'becomes', 'in', 'they', 'themselves', ',', 'happenings', 'on', 'Moreover', 'most', 'latest', 'aspect', 'find', 'newspapers', 'person', 'always', 'education', 'through', 'India', 'social', 'important', 'The', 'possible', 'away', 'All', 'depending', 'requires', 'numerous', '.', 'now', 'A', 'from', 'and', 'happening', 'America', 'Students', 'socially', 'sitting', 'information', 'live', 'at', 'advantages', 'a', 'You', 'When', 'lectures', 'one', 'just', 'can', 'aware', 'click', 'educate', 'device', 'various', 'more', 'attend', 'media', 'lecture', 'for', 'of', 'because', 'positive', 'are', 'is', 'as', 'updated', 'look', 'world', 'distancing', 'using', 'while', 'topics'}\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "word=set(nltk.word_tokenize(text))\n",
    "print(word)\n",
    "print(len(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['news', 'people', 'issues', 'Furthermore', 'great', 'becomes', ',', 'happenings', 'Moreover', 'latest', 'aspect', 'find', 'newspapers', 'person', 'always', 'education', 'India', 'social', 'important', 'The', 'possible', 'away', 'All', 'depending', 'requires', 'numerous', '.', 'A', 'happening', 'America', 'Students', 'socially', 'sitting', 'information', 'live', 'advantages', 'You', 'When', 'lectures', 'one', 'aware', 'click', 'educate', 'device', 'various', 'attend', 'media', 'lecture', 'positive', 'updated', 'look', 'world', 'distancing', 'using', 'topics']\n"
     ]
    }
   ],
   "source": [
    "#removal of stop words from text\n",
    "\n",
    "filtered = []\n",
    "for i in word:\n",
    "    if i not in stop_word:\n",
    "        filtered.append(i)\n",
    "print(filtered)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When we look at the positive aspect of social media.', 'we find numerous advantages.', 'The most important being a great device for education.', 'All the information one requires is just a click away.', 'Students can educate themselves on various topics using social media.', 'Moreover, live lectures are now possible because of social media.', 'You can attend a lecture happening in America while sitting in India.', 'Furthermore, as more and more people are distancing themselves from newspapers, they are depending on social media for news.', 'You are always updated on the latest happenings of the world through it.', 'A person becomes more socially aware of the issues of the world.'] 10\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "text = '''When we look at the positive aspect of social media. we find numerous advantages. The most important being a great device for education. \n",
    "          All the information one requires is just a click away. Students can educate themselves on various topics using social media.\n",
    "          Moreover, live lectures are now possible because of social media. You can attend a lecture happening in America while sitting in India.\n",
    "          Furthermore, as more and more people are distancing themselves from newspapers, they are depending on social media for news. You are always updated on the latest happenings of the world through it. A person becomes more socially aware of the issues of the world.\n",
    "        '''\n",
    "sentnce = nltk.sent_tokenize(text)\n",
    "print(sentnce,len(sentnce))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'look', 'posit', 'aspect', 'social', 'media', '.']\n",
      "['find', 'numer', 'advantag', '.']\n",
      "['the', 'import', 'great', 'devic', 'educ', '.']\n",
      "['all', 'inform', 'one', 'requir', 'click', 'away', '.']\n",
      "['student', 'educ', 'variou', 'topic', 'use', 'social', 'media', '.']\n",
      "['moreov', ',', 'live', 'lectur', 'possibl', 'social', 'media', '.']\n",
      "['you', 'attend', 'lectur', 'happen', 'america', 'sit', 'india', '.']\n",
      "['furthermor', ',', 'peopl', 'distanc', 'newspap', ',', 'depend', 'social', 'media', 'news', '.']\n",
      "['you', 'alway', 'updat', 'latest', 'happen', 'world', '.']\n",
      "['A', 'person', 'becom', 'social', 'awar', 'issu', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "for i in range(len(sentnce)):\n",
    "    words= nltk.word_tokenize(sentnce[i])\n",
    "    words= [stemmer.stem(word) for word in words if word not in stop_word]\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "for i in range(len(sentnce)):\n",
    "    words= nltk.word_tokenize(sentnce[i])\n",
    "    words= [stemmer.stem(word) for word in words if word not in stop_word]\n",
    "    sentnce[i]=' '.join(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when look posit aspect social media .',\n",
       " 'find numer advantag .',\n",
       " 'the import great devic educ .',\n",
       " 'all inform one requir click away .',\n",
       " 'student educ variou topic use social media .',\n",
       " 'moreov , live lectur possibl social media .',\n",
       " 'you attend lectur happen america sit india .',\n",
       " 'furthermor , peopl distanc newspap , depend social media news .',\n",
       " 'you alway updat latest happen world .',\n",
       " 'A person becom social awar issu world .']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentnce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>when look posit aspect social media .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>find numer advantag .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>the import great devic educ .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>all inform one requir click away .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>student educ variou topic use social media .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>moreov , live lectur possibl social media .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>you attend lectur happen america sit india .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>furthermor , peopl distanc newspap , depend so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>you alway updat latest happen world .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>A person becom social awar issu world .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0              when look posit aspect social media .\n",
       "1                              find numer advantag .\n",
       "2                      the import great devic educ .\n",
       "3                 all inform one requir click away .\n",
       "4       student educ variou topic use social media .\n",
       "5        moreov , live lectur possibl social media .\n",
       "6       you attend lectur happen america sit india .\n",
       "7  furthermor , peopl distanc newspap , depend so...\n",
       "8              you alway updat latest happen world .\n",
       "9            A person becom social awar issu world ."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize data(sentences) using data frames\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(sentnce)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['look', 'posit', 'aspect', 'social', 'media', '.', 'find', 'numer', 'advantag', '.', 'import', 'great', 'devic', 'educ', '.', 'inform', 'one', 'requir', 'click', 'away', '.', 'student', 'educ', 'variou', 'topic', 'use', 'social', 'media', '.', 'moreov', ',', 'live', 'lectur', 'possibl', 'social', 'media', '.', 'attend', 'lectur', 'happen', 'america', 'sit', 'india', '.', 'furthermor', ',', 'peopl', 'distanc', 'newspap', ',', 'depend', 'social', 'media', 'news', '.', 'alway', 'updat', 'latest', 'happen', 'world', '.', 'A', 'person', 'becom', 'social', 'awar', 'issu', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "a=[]\n",
    "stemmer = PorterStemmer()\n",
    "for i in range(len(sentnce)):\n",
    "    words= nltk.word_tokenize(sentnce[i])\n",
    "   # print(len(words))\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in stop_word:\n",
    "    \n",
    "            words= stemmer.stem(word)\n",
    "            sentnce[i]=' '.join(words)\n",
    "            a.append(words)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
